{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_dicts = {'Lot Shape': {'Reg': 3, 'IR1': 2, 'IR2': 1, 'IR3': 0},\n",
    "                 'Utilities': {'AllPub': 3, 'NoSewr': 2, 'NoSeWa': 1, 'ELO': 0},\n",
    "                 'Land Slope': {'Gtl': 2, 'Mod': 1, 'Sev': 0},\n",
    "                 'Exter Qual': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0},\n",
    "                 'Exter Cond': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0},\n",
    "                 'Bsmt Qual': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
    "                 'Bsmt Cond': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
    "                 'Bsmt Exposure': {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0},\n",
    "                 'BsmtFin Type 1': {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'NA': 0},\n",
    "                 'BsmtFin Type 2': {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'NA': 0},\n",
    "                 'Heating QC': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0},\n",
    "                 'Electrical': {'SBrkr': 4, 'FuseA': 3, 'FuseF': 2, 'FuseP': 1, 'Mix': 0},\n",
    "                 'Kitchen Qual': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0},\n",
    "                 'Fireplace Qu': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
    "                 'Functional': {'Typ': 7, 'Min1': 6, 'Min2': 5, 'Mod': 4, 'Maj1': 3, 'Maj2': 2, 'Sev': 1, 'Sal': 0},\n",
    "                 'Garage Finish': {'Fin': 3, 'RFn': 2, 'Unf': 1, 'NA': 0},\n",
    "                 'Garage Qual': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
    "                 'Garage Cond': {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
    "                 'Paved Drive': {'Y': 2, 'P': 1, 'N': 0},\n",
    "                 'Pool QC': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'NA': 0},\n",
    "                 'Fence': {'GdPrv': 4, 'MnPrv': 3, 'GdWo': 2, 'MnWw': 1, 'NA': 0}\n",
    "                }\n",
    "\n",
    "nominal_cols = ['PID', 'MS SubClass', 'MS Zoning', 'Land Contour', 'Street',\n",
    "                 'Alley', 'Lot Config', 'Neighborhood', 'Condition 1',\n",
    "                 'Condition 2', 'Bldg Type', 'House Style', 'Roof Style',\n",
    "                 'Roof Matl', 'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Type',\n",
    "                 'Foundation', 'Garage Type', 'Misc Feature', 'Heating',\n",
    "                 'Central Air', 'Sale Type']\n",
    "\n",
    "ordinal_cols = ['Lot Shape', 'Utilities', 'Land Slope', 'Overall Qual',\n",
    "                 'Overall Cond', 'Exter Qual', 'Exter Cond', 'Bsmt Qual',\n",
    "                 'Bsmt Cond', 'Bsmt Exposure', 'BsmtFin Type 1',\n",
    "                 'BsmtFin Type 2', 'Heating QC', 'Electrical', 'Kitchen Qual',\n",
    "                 'Fireplace Qu', 'Functional', 'Garage Finish', 'Garage Qual',\n",
    "                 'Garage Cond', 'Paved Drive', 'Pool QC', 'Fence']\n",
    "    \n",
    "discrete_cols = ['Year Built', 'Year Remod/Add', 'Bsmt Full Bath',\n",
    "                 'Bsmt Half Bath', 'Full Bath', 'Half Bath', 'Bedroom AbvGr',\n",
    "                 'Kitchen AbvGr', 'TotRms AbvGrd', 'Fireplaces', 'Garage Yr Blt',\n",
    "                 'Garage Cars', 'Mo Sold', 'Yr Sold']\n",
    "\n",
    "continuous_cols = ['Lot Frontage', 'Lot Area', 'Mas Vnr Area', 'BsmtFin SF 1',\n",
    "                   'BsmtFin SF 2', 'Bsmt Unf SF', 'Total Bsmt SF', '1st Flr SF',\n",
    "                   '2nd Flr SF', 'Low Qual Fin SF', 'Gr Liv Area', 'Garage Area',\n",
    "                   'Wood Deck SF', 'Open Porch SF', 'Enclosed Porch', '3Ssn Porch',\n",
    "                   'Screen Porch', 'Pool Area', 'Misc Val', 'SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    '''Cleans and preprocesses dataframe.  \n",
    "    Returned dataframe has all numeric columns.'''\n",
    "    df = replace_nan(df)\n",
    "    df = convert_ordinal(df)\n",
    "    df = make_dummies(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ordinal(df):\n",
    "    '''Preprocess helper function. Takes data-\n",
    "    frame with unmapped ordinal columns and\n",
    "    returns dataframe with mapped ordinal.'''\n",
    "    for col in df:\n",
    "        if col in ordinal_dicts.keys():\n",
    "            df[col] = df[col].map(ordinal_dicts[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dummies(df):\n",
    "    '''Preprocess helper function. Takes data-\n",
    "    frame with nominal columns represented as\n",
    "    strings and returns dataframe with nominal\n",
    "    columns removed and replaced with dummies.'''\n",
    "    for col in df.columns:\n",
    "        if col in nominal_cols:\n",
    "            df = pd.get_dummies(data=df, columns = [col], drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan(df):\n",
    "    '''Preprocess helper function. Takes data-\n",
    "    frame with NaN values and returns dataframe\n",
    "    with NaNs replaced with 0 or \"NA\" depending \n",
    "    on column dtype.'''\n",
    "    for col in df.columns:\n",
    "        if (df[col].dtype == np.float64 or df[col].dtype == np.int64):\n",
    "              df[col].fillna(0,inplace = True)\n",
    "        else:\n",
    "              df[col].fillna('NA',inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_corr_heatmap(df,target,title_prefix=\"\",save=False):\n",
    "    '''EDA helper function. Takes dataframe and\n",
    "    target column to compare correlation values \n",
    "    against. Displays heatmap with option to save\n",
    "    as file and augment figure title.'''\n",
    "    corr = df.corr()\n",
    "    plt.figure(figsize=(16,9))\n",
    "    corr_hmap = sns.heatmap(corr[[target]].sort_values(by=target,\n",
    "                                                       ascending=False),\n",
    "                            vmin=-1,\n",
    "                            vmax=1,\n",
    "                            annot= True,\n",
    "                            cmap='icefire');\n",
    "    title_name = title_prefix+'Features Correlation with '+target\n",
    "    plt.title(title_name,size=20)\n",
    "    if save:\n",
    "        fname = \"\".join(title_name.split())\n",
    "        plt.savefig(fname+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_histograms(df,h,k,save=False,fname=\"untitled_hist\"):\n",
    "    '''EDA helper function. Takes dataframe and\n",
    "    plt subplot dimensions to display distributions\n",
    "    of columns as seaborn distplots. Option to save\n",
    "    figure as file.'''\n",
    "    plt.figure(figsize=(16,9))\n",
    "    sns.set_style('darkgrid')\n",
    "    f, axes = plt.subplots(h, k, figsize=(25, 9), sharex=False);\n",
    "    for i in range(h):\n",
    "        for j in range(k):\n",
    "            sns.distplot(df[features[i*h+j]], ax=axes[i, j], hist=True, kde=False, bins=100);\n",
    "    if save:\n",
    "        plt.savefig(fname+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(df, features, target, print_metrics=True, save=False, fname = \"untitled_metrics\"):\n",
    "    '''Function to streamline preprocessing, model \n",
    "    selection, modeling, and model evalution. Takes \n",
    "    dataframe, features, target, and flags to save\n",
    "    or print evalution results. Returns selected \n",
    "    model and final feature columns.'''\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    X = preprocess(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 42)\n",
    "    \n",
    "    mod = find_optimal_regression(X_train, y_train)\n",
    "    \n",
    "    rmse_sum = 0\n",
    "    r2_sum = 0\n",
    "    cross_val_sum = 0\n",
    "    n = 10\n",
    "    \n",
    "    for rand in range(n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = rand)\n",
    "    \n",
    "        mod.fit(X_train, y_train)\n",
    "        for col in X_train.columns:\n",
    "            if X_train[col].isnull().sum() != 0:\n",
    "                print(col)\n",
    "        pipescore = mod.score(X_test,y_test)\n",
    "        r2_sum += pipescore\n",
    "        y_preds = mod.predict(X_test)\n",
    "        rmse_sum += mean_squared_error(y_test, y_preds, squared=False)\n",
    "        cross_val_sum += cross_val_score(mod, X_train, y_train).mean()\n",
    "    \n",
    "    evals = f\"\\n\\nR2: {round(r2_sum/n,2)}\\n\\nRMSE: {round(rmse_sum/n,2)}\\n\\nCrossVal: {round(cross_val_sum/n,2)}\\n\\n\"\n",
    "    \n",
    "    if save:\n",
    "        file = open(fname+\".txt\", \"x\")\n",
    "        file.write(features)\n",
    "        file.write(evals)\n",
    "        file.write(mod)\n",
    "        file.close()\n",
    "    \n",
    "    if print_metrics:\n",
    "        print(evals)\n",
    "        print(mod)\n",
    "    \n",
    "    return mod,X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha range code taken from Analytics Vidhya\n",
    "# https://www.analyticsvidhya.com/blog/2016/01/ridge-lasso-regression-python-complete-tutorial/\n",
    "def find_optimal_regression(X_train, y_train):\n",
    "    \n",
    "    '''Model selection and tuning function. Uses \n",
    "    GridSearch to iterate over 7 potential alpha\n",
    "    values for both ridge and lasso. Returns best\n",
    "    scoring model between ridge, lasso, and linear\n",
    "    regression with no regularization.'''\n",
    "    \n",
    "    ridge_grid = {'alpha': [1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}\n",
    "    lasso_grid = {'alpha': [1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}\n",
    "    \n",
    "    ridge_gridsearch = GridSearchCV(estimator=Ridge(),\n",
    "                              param_grid=ridge_grid,\n",
    "                              cv=5,\n",
    "                              verbose=1)\n",
    "    \n",
    "    lasso_gridsearch = GridSearchCV(estimator=Ridge(),\n",
    "                              param_grid=ridge_grid,\n",
    "                              cv=5,\n",
    "                              verbose=1)\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    ridge_gridsearch.fit(X_train, y_train)\n",
    "    lasso_gridsearch.fit(X_train, y_train)\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    lr_score = cross_val_score(lr,X_train,y_train).mean()\n",
    "    ridge_score = ridge_gridsearch.best_score_\n",
    "    lasso_score = lasso_gridsearch.best_score_\n",
    "    \n",
    "    scores = [lr_score, ridge_score, lasso_score]\n",
    "    \n",
    "    if max(scores)==ridge_score:\n",
    "        return ridge_gridsearch.best_estimator_\n",
    "    elif max(scores)==lasso_score:\n",
    "        return lasso_gridsearch.best_estimator_\n",
    "    else:\n",
    "        return lr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All functions below this point were not used in Project 2 ##\n",
    "But I will keep them here for my future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline(X_train, y_train):\n",
    "    model = find_optimal_regression(X_train, y_train)\n",
    "    pipe = Pipeline([('ss', StandardScaler()),\n",
    "                    (str(type(model)),model)])\n",
    "    return pipe,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(X, y):\n",
    "\n",
    "    \n",
    "    imp_num = FunctionTransformer(imputer_numeric)\n",
    "    ss = StandardScaler()\n",
    "    \n",
    "    imp_cat = FunctionTransformer(imputer_categorical)\n",
    "    ord_enc = FunctionTransformer(convert_ordinal)\n",
    "    ohe = OneHotEncoder(drop='first',handle_unknown='error')\n",
    "    \n",
    "    num_cols = [col for col in X.columns if (X[col].dtype == np.int64 or X[col].dtype == np.float64)]\n",
    "    cat_cols = [col for col in X.columns if (col not in num_cols)]\n",
    "    ord_cols = [col for col in X.columns if (col in ordinal_dicts.keys())]\n",
    "    nom_cols = [col for col in X.columns if (col in nominal_cols)]\n",
    "    \n",
    "    ord_nom_trans = ColumnTransformer([('ord', ord_enc, ord_cols),\n",
    "                                  ('nom', ohe, nom_cols)])\n",
    "    #nom_trans = ColumnTransformer([('nom', ohe, nom_cols)])\n",
    "    \n",
    "    num_pip = Pipeline([('imp_num', imp_num), ('scale', ss)])\n",
    "    cat_pip = Pipeline([('imp_cat', imp_cat), ('ord_nom', ord_nom_trans)])\n",
    "    \n",
    "    preprocessing = ColumnTransformer([('numerical', num_pip, num_cols), ('categorical', cat_pip, cat_cols)],remainder='passthrough')\n",
    "\n",
    "    X = cat_pip.fit_transform(X)\n",
    "    print(X)\n",
    "    X = ord_nom_trans.fit_transform(X)\n",
    "    print(type(X))\n",
    "    X = num_pip.fit_transform(X)\n",
    "    \n",
    "    \n",
    "    #model = find_optimal_regression(X_train, y_train)\n",
    "    \n",
    "    # Make pipeline\n",
    "    pipe = Pipeline([('preprocess', preprocessing),\n",
    "                    ('linreg', LinearRegression())])\n",
    "                    #(str(type(model)),model)])\n",
    "    \n",
    "    return pipe    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes: dataframe and list of tuples of columns to make interacting\n",
    "# Returns: dataframe with interacting variables \n",
    "def generate_interactor(df,variables):\n",
    "    \n",
    "    for a,b in variables:\n",
    "        df[a+\" X \"+b] = df[a]*df[b]\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes: dataframe, target variable, list of tuple columns to evaluate interacting\n",
    "# Prints: coefficients and p-values for each interactor\n",
    "def evaluate_interactor(df,features,target):\n",
    "    poly = PolynomialFeatures(include_bias = False)\n",
    "    X = df[features]\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    poly_df = pd.DataFrame(X_poly, columns=poly.get_feature_names(features))\n",
    "    poly_df[target] = df[target]\n",
    "    display_corr_heatmap(poly_df,target,title_prefix=\"Polynomial \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
